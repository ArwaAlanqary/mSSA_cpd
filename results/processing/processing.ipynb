{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_average_df(algorithms, data_sets, results_path, output_path): \n",
    "    output = {}\n",
    "    for algorithm in algorithms: \n",
    "        output[algorithm] = {}\n",
    "        for data_set in data_sets: \n",
    "            results = pd.read_csv(os.path.join(results_path, algorithm, data_set,'results_table.csv'), header=None)\n",
    "            results = results[4].values\n",
    "            output[algorithm][data_set] = str(round(np.mean(results), 3)) + \" (\" + str(round(np.std(results),3)) +\")\" \n",
    "    output_df = pd.DataFrame.from_dict(output)\n",
    "    output_df.to_latex(os.path.join(output_path, 'average_f1_table.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_histograms(algorithms, data_sets, results_path, output_path, data_path):\n",
    "    output = {}\n",
    "    for algorithm in algorithms: \n",
    "        output[algorithm] = {}\n",
    "        for data_set in data_sets: \n",
    "            files = glob.glob(os.path.join(results_path, algorithm, data_set, '*.json'))\n",
    "            ARL = []\n",
    "            for file in files: \n",
    "                with open(file) as f:\n",
    "                    result = json.load(f)\n",
    "                ts_name = result['data_name']\n",
    "                detected = np.array(result['cp'])[:, 0]\n",
    "                labels = pd.read_csv(os.path.join(data_path, data_set,\"{}_labels.csv\".format(ts_name)), header=None)\n",
    "                labels = labels.values[:,0]\n",
    "                for cp in detected:\n",
    "                    dist = labels-cp\n",
    "                    index = np.argmin(np.abs(labels-cp))\n",
    "                    ARL.append(dist[index])\n",
    "            output[algorithm][data_set] = str(round(np.mean(np.abs(ARL)), 3)) + \" (\" + str(round(np.std(np.abs(ARL)), 3)) +\"), \" + str(round(np.median(np.abs(ARL)), 3)) \n",
    "            fig = plt.figure(figsize=(6,4))\n",
    "            plt.hist(ARL, bins = 20, color = 'g', alpha=0.7)\n",
    "            plt.title('{}_{}'.format(data_set, algorithm))\n",
    "            fig.savefig('{}/{}_{}'.format(output_path, data_set, algorithm), dpi = 400)\n",
    "    output_df = pd.DataFrame.from_dict(output)\n",
    "    output_df.to_latex(os.path.join(output_path, 'arl_table.txt'))\n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), 'data')\n",
    "results_path = os.path.join(os.path.dirname(os.getcwd()), 'test')\n",
    "output_path = os.path.join(os.path.dirname(os.getcwd()), 'processing')\n",
    "algorithms = ['binseg', 'microsoft_ssa', 'hybrid_cusum', 'hybrid_cusum_moving_window']\n",
    "data_sets = ['yahoo', 'struct', 'mean', 'energy']\n",
    "generate_average_df(algorithms, data_sets, results_path, output_path)\n",
    "generate_histograms(algorithms, data_sets, results_path, output_path, data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
